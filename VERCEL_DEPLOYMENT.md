# Vercel Deployment Guide

## ğŸš€ Ready for Vercel Deployment!

Your chatbot has been prepared for Vercel with the following changes:

### âœ… What I've Added:
- `vercel.json` - Vercel configuration
- `api/index.py` - Serverless function version of your chatbot
- Simplified keyword-based intent matching (faster for serverless)

### ğŸ“ New Project Structure:
```
Chatbot/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ index.py          # Serverless Flask app
â”œâ”€â”€ chatbot_server.py     # Original local development version
â”œâ”€â”€ chatbot.py           # CLI version
â”œâ”€â”€ chatbot.html         # Web interface
â”œâ”€â”€ intents.json         # Training data
â”œâ”€â”€ requirements.txt     # Dependencies
â”œâ”€â”€ vercel.json          # Vercel config
â””â”€â”€ README.md            # Documentation
```

### ğŸ”§ Deployment Steps:

1. **Install Vercel CLI:**
   ```bash
   npm install -g vercel
   ```

2. **Deploy from your project directory:**
   ```bash
   cd C:\Users\akil2\OneDrive\Desktop\chat\Chatbot
   vercel
   ```

3. **Follow the prompts:**
   - Link to existing project or create new
   - Select Python runtime
   - Deploy!

### âš ï¸ Important Notes:

- **Simplified AI**: Used keyword matching instead of ML for faster serverless performance
- **Cold Starts**: First request may be slower
- **Static Files**: HTML/CSS served directly by Vercel
- **Original Version**: Keep `chatbot_server.py` for local development with full ML

### ğŸ”„ Alternative: Keep Full ML Version

If you want the full NLTK+scikit-learn version on Vercel:
- Expect slower cold starts (3-10 seconds)
- Higher memory usage
- NLTK downloads on first run

Let me know if you want to deploy the full ML version instead!